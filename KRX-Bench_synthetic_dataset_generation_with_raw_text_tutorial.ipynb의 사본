{"cells":[{"cell_type":"markdown","source":["# KRX-Bench 합성 데이터셋 생성 with raw text 튜토리얼\n","\n","- **litellm**은 다양한 LLM API를 OpenAI API로 통합하여 사용할 수 있는 라이브러리입니다.\n","- 본 튜토리얼에서는 OpenAI의 `gpt-4o-mini-2024-07-18` 모델을 활용하여 금융 관련 고품질 raw text 데이터셋 `alvanlii/finance-textbooks`을 QA Instruction 데이터셋으로 변환하는 방법에 대해 다룹니다.\n","- 데이터 생성 파이프라인:\n"," 1. LLM에게 샘플링된 raw text를 입력으로 해서 질문 세트 생성\n"," 2. 생성된 질문 세트에 대한 답변 생성"],"metadata":{"id":"kf_QmyI_rMBg"},"id":"kf_QmyI_rMBg"},{"cell_type":"markdown","source":["## 1. litellm 설치 및 환경 설정\n","- 필요 라이브러리: pandas, datasets, random, litellm, os"],"metadata":{"id":"uBGB4FQtvOfT"},"id":"uBGB4FQtvOfT"},{"cell_type":"code","source":["!pip install datasets litellm==1.44.9"],"metadata":{"id":"7mykcLNcvV8V"},"id":"7mykcLNcvV8V","execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","from datasets import load_dataset, Dataset\n","import random\n","from litellm import completion, batch_completion\n","import os\n","import litellm\n","\n","# OpenAI API key 선언\n","os.environ[\"OPENAI_API_KEY\"] = \"sk-xxx...\""],"metadata":{"id":"xAO8VwfKkcmI"},"id":"xAO8VwfKkcmI","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2. 함수 선언\n","\n","- 본 튜토리얼에서 사용하는 데이터셋인 `alvanlii/finance-textbooks`는 긴 길이의 텍스트 데이터로 구성되어 있기 때문에 적절한 길이의 데이터로 샘플링하는 작업이 필요합니다.\n","- `get_random_section`함수는 매우 긴 텍스트에서 무작위로 일부분을 샘플링하기 위한 함수로, 이 함수를 활용하면 긴 텍스트 데이터에서 적절한 길이의 텍스트 데이터를 샘플링해서 사용할 수 있습니다."],"metadata":{"id":"XWfU2WwJsb38"},"id":"XWfU2WwJsb38"},{"cell_type":"code","execution_count":null,"id":"1e740732-b02d-4045-9954-cb37a755a8cd","metadata":{"scrolled":true,"id":"1e740732-b02d-4045-9954-cb37a755a8cd"},"outputs":[],"source":["def get_random_section(long_string, length=1000):\n","    if len(long_string) <= length:\n","        return long_string\n","\n","    start_index = random.randint(0, len(long_string) - length)\n","\n","    return long_string[start_index:start_index + length]"]},{"cell_type":"markdown","source":["## 3. 데이터셋 로드 및 전처리\n","\n","- `alvanlii/finance-textbooks` 데이터셋은 금융 관련 고품질 raw text 데이터셋으로 instruction 형태가 아닌 raw text로 구성되어 있습니다.\n","- 데이터의 길이가 굉장히 길기 때문에 사전의 정의한 `get_random_section` 함수로 샘플링을 진행한 뒤 활용합니다."],"metadata":{"id":"zEscvx1vtDPI"},"id":"zEscvx1vtDPI"},{"cell_type":"code","source":["# 데이터셋 로드\n","ds = load_dataset('alvanlii/finance-textbooks')['train']\n","\n","# 데이터셋 샘플링 - get_random_section\n","texts = []\n","for bt in ds['book_text']:\n","    for i in range(2):\n","        texts.append(get_random_section(bt, 2048))"],"metadata":{"id":"wMUfQvA0tPm9"},"id":"wMUfQvA0tPm9","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4. 합성 데이터셋 생성\n","\n","합성 데이터셋 생성 파이프라인은 다음과 같습니다.\n","1. 샘플링된 raw text 데이터를 사용해서 질문 데이터셋을 생성합니다.\n","2. 생성된 질문 데이터셋에 대한 답변을 생성합니다."],"metadata":{"id":"oLYbeE8Ptszz"},"id":"oLYbeE8Ptszz"},{"cell_type":"code","source":["# chat prompt 포맷팅\n","qrys = []\n","for t in texts:\n","    messages = [\n","    {\"content\":\"Your job is creating multi-hop reasoning questions in fluent Korean. You will be given a part of a text. Make a question based on it. The question should require multiple steps of reasoning related to the text. Return the question only without any other text.\",\"role\":\"system\"},\n","    { \"content\": t,\"role\": \"user\"}]\n","    qrys.append(messages)\n","\n","# 1. raw text 데이터를 활용한 질문 생성\n","responses = batch_completion(\n","    model=\"gpt-4o-mini-2024-07-18\",\n","    messages = qrys\n",")\n","resps = [i.choices[0].message.content for i in responses]\n","total_prompt_tokens_for_q = sum([r.usage.prompt_tokens for r in responses])\n","total_completion_tokens_for_q = sum([r.usage.completion_tokens for r in responses])\n","df = pd.DataFrame({'sampled_text':texts,'question':resps})"],"metadata":{"id":"FISvhwF5uc4V"},"id":"FISvhwF5uc4V","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"4ffebe8a-1b45-4ac8-876b-072ad413b3c7","metadata":{"id":"4ffebe8a-1b45-4ac8-876b-072ad413b3c7"},"outputs":[],"source":["# 답변 생성용 prompt 포맷팅\n","qrys = []\n","for t in resps:\n","    messages = [\n","    {\"content\":\"You are a skilled financial expert in Korea. Make a response for the question. DO NOT introduce yourself.\",\"role\":\"system\"},\n","    { \"content\": t,\"role\": \"user\"}]\n","    qrys.append(messages)\n","\n","# 2. 생성된 질문에 대한 답변 생성\n","responses = batch_completion(\n","    model=\"gpt-4o-mini-2024-07-18\",\n","    messages = qrys\n",")\n","resps = [i.choices[0].message.content for i in responses]\n","df['response'] = resps\n","total_prompt_tokens_for_a = sum([r.usage.prompt_tokens for r in responses])\n","total_completion_tokens_for_a = sum([r.usage.completion_tokens for r in responses])"]},{"cell_type":"markdown","source":["## 5. 데이터셋 생성 비용 확인"],"metadata":{"id":"9ENFxEQnuPi5"},"id":"9ENFxEQnuPi5"},{"cell_type":"code","execution_count":null,"id":"1da7c113-3214-46ea-97d4-bb73d4d7571e","metadata":{"id":"1da7c113-3214-46ea-97d4-bb73d4d7571e"},"outputs":[],"source":["print('total prompt tokens:', total_prompt_tokens_for_q + total_prompt_tokens_for_a)\n","print('prompt token costs: $', round((total_prompt_tokens_for_q + total_prompt_tokens_for_a) / 1000000 * 0.150, 6))\n","print('total completion tokens:', total_completion_tokens_for_q + total_completion_tokens_for_a)\n","print('completion token costs: $', round((total_completion_tokens_for_q + total_completion_tokens_for_a) / 1000000 * 0.600, 6))"]},{"cell_type":"markdown","source":["## 6. 데이터셋 저장 및 확인"],"metadata":{"id":"0VNB896iuatY"},"id":"0VNB896iuatY"},{"cell_type":"code","execution_count":null,"id":"5c39ae9a-f9af-4f2d-bf08-ebd20042a708","metadata":{"id":"5c39ae9a-f9af-4f2d-bf08-ebd20042a708"},"outputs":[],"source":["# CSV 파일 저장\n","df.to_csv(\"output_path/result.csv\")\n","\n","# Excel 파일 저장\n","df.to_excel(\"output_path/result.xlsx\")\n","\n","# HuggingFace Hub 업로드 - token에 개인 HuggingFace 토큰을 입력해주시면 됩니다.\n","result_df = Dataset.from_pandas(df)\n","result_df.push_to_hub(\"hf/dataset\", token=\"HF_TOKEN\")\n","\n","df.head()"]},{"cell_type":"markdown","source":["## 참고자료\n","\n","- [alvanlii/finance-textbooks](https://huggingface.co/datasets/alvanlii/finance-textbooks)\n","- [litellm Docs](https://docs.litellm.ai/)\n","- [Cosmopedia GitHub](https://github.com/huggingface/cosmopedia)\n","- [Cosmopedia Blog](https://huggingface.co/blog/cosmopedia)\n","- [Textbooks Are All You Need](https://arxiv.org/pdf/2306.11644)\n","- [Learning to Generate Instruction Tuning Datasets for Zero-Shot Task Adaptation](https://arxiv.org/abs/2402.18334)"],"metadata":{"id":"eOGRk0pUrcv1"},"id":"eOGRk0pUrcv1"}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"colab":{"provenance":[{"file_id":"1QCrjL7M27ox_YyyrDslj4P6_mkE5a38G","timestamp":1729064998701}]}},"nbformat":4,"nbformat_minor":5}